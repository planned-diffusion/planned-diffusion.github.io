<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Planned Diffusion: A Hybrid Approach to Fast and High-Quality Text Generation">
  <meta name="keywords"
    content="Planned Diffusion, Large Language Models, LLMs, Diffusion Models, Autoregressive, Text Generation, Machine Learning, NLP, Artificial Intelligence">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Planned Diffusion</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="data:,">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Planned Diffusion</h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://danielmisrael.github.io/">Daniel Israel</a><sup>1*</sup>,</span>
              <span class="author-block"><a href="https://www.tjin.org/">Tian Jin</a><sup>2*</sup>,</span>
              <span class="author-block"><a href="https://elliecheng.com/">Ellie Cheng</a><sup>2</sup>,</span>
              <span class="author-block"><a href="https://web.cs.ucla.edu/~guyvdb/">Guy Van den Broeck</a><sup>1</sup>,</span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://aditya-grover.github.io/">Aditya Grover</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://people.csail.mit.edu/suvinay/">Suvinay Subramanian</a><sup>3</sup>,</span>
              <span class="author-block"><a href="https://people.csail.mit.edu/mcarbin/">Michael Carbin</a><sup>2</sup></span>
            </div>

            <div class="is-size-5 publication-authors" style="margin-top: 0.5rem;">
              <span class="author-block" style="margin: 0 1rem;"><sup>1</sup>UCLA</span>
              <span class="author-block" style="margin: 0 1rem;"><sup>2</sup>MIT</span>
              <span class="author-block" style="margin: 0 1rem;"><sup>3</sup>Google</span>
            </div>
            <div class="is-size-6 publication-authors" style="margin-top: 0.5rem;">
              <span class="author-block"><sup>*</sup>Equal contribution</span>
            </div>
          </div>
        </div>

        <div class="columns is-centered">
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Paper Link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2510.18087" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link -->
              <span class="link-block">
                <a href="https://github.com/planned-diffusion/planned-diffusion" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" style="padding-top: 0rem; margin-top: -2rem;">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <!-- TL;DR Section -->
          <div class="content is-size-5 has-text-centered">
            <em><strong>TL;DR:</strong> Planned diffusion speeds up LLM inference by denoising spans of text in parallel from a previously generated plan.</em>
          </div>
          <div class="publication-image">
            <img src="./static/images/intro-fig.png" alt="Planned Diffusion Overview" class="responsive-image"
              loop autoplay style="width: 100%;">
          </div>
        </div>
      </div>

      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              A central challenge in large language model inference is the trade-off between generation speed and output quality. Autoregressive models produce high-quality text but generate tokens sequentially. 
              Diffusion models can generate tokens in parallel but often need many iterations to match the same quality. 
              We propose <em>planned diffusion</em>, a hybrid method that combines the strengths of both paradigms.
              Planned diffusion works in two stages: first, the model creates a short autoregressive outline that breaks the output into smaller, independent spans. 
              Second, the model generates these spans simultaneously using diffusion. This approach expands the speedâ€“quality Pareto frontier and provides a practical path to faster, high-quality text generation.
              On AlpacaEval, a suite of 805 instruction-following prompts, planned diffusion achieves Pareto-optimal trade-off between quality and latency, achieving 1.84x speedup over autoregressive generation with only a 6.8% drop in win rate.
              Our sensitivity analysis confirms that the internal planning of our model is reliable and offers tunable control over the trade-off between generation speed and quality.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{israel2025planneddiffusion,
      title={Planned Diffusion},
      author={Daniel Israel and Tian Jin and Ellie Cheng and Guy Van den Broeck and Aditya Grover and Suvinay Subramanian and
      Michael Carbin},
      year={2025},
      eprint={2510.18087},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2510.18087}
  }
</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://nerfies.github.io/">Nerfies project page</a>.
            </p>
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
              You are free to borrow the of this website, we just ask that you link back to this page in the footer.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>